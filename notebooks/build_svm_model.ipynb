{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from course_utils import trainTest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from models import evaluate_accuracy\n",
    "import models\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import pickler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO: \n",
    "- Run on larger data set \n",
    "- lower min-n-gram count\n",
    "- try TF-IDF True or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydat = pickler.load_object('../data/data_and_labels.pkl')\n",
    "X = mydat['X']\n",
    "y = mydat['y']\n",
    "ordered_case_ids = mydat['ordered_case_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'randint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9baecdf04f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0msample_pct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'randint'"
     ]
    }
   ],
   "source": [
    "def subsample(X,y,case_ids, sample_pct):\n",
    "    print sample_pct\n",
    "    \n",
    "np.randint(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split(X,y, ordered_case_ids,pct_train):\n",
    "    train_rows = int(pct_train*len(y))\n",
    "    y_train = np.array(y[:train_rows])\n",
    "    y_test = np.array(y[train_rows:])\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    case_ids_train = ordered_case_ids[:train_rows]\n",
    "    case_ids_test = ordered_case_ids[train_rows:]\n",
    "    return X_train,y_train,case_ids_train,X_test,y_test,case_ids_test\n",
    "\n",
    "X_train,y_train,case_ids_train,X_test,y_test,case_ids_test = train_test_split(X,y,ordered_case_ids,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11599, 351415)\n",
      "(3867, 351415)\n",
      "(11599,)\n",
      "(3867,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Baseline Model\n",
    "The base line majority classifier model to beat is 54% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 2154 \t 0 \t 0\n",
      "\t 2 \t 627 \t 0 \t 0\n",
      "\t 3 \t 1086 \t 0 \t 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55702094647013189"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)\n",
    "mclf = models.MajorityClassifier()\n",
    "mclf.fit(X_train,y_train)\n",
    "\n",
    "evaluate_accuracy(y_test,mclf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Out-of-the-Box SVM\n",
    "Gets accuracy of 39%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(penalty='l1',random_state=0, dual=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57124385828807867"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 5013 \t 87 \t 551\n",
      "\t 2 \t 364 \t 1213 \t 263\n",
      "\t 3 \t 797 \t 81 \t 3230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81524269333563237"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 1736 \t 69 \t 349\n",
      "\t 2 \t 382 \t 98 \t 147\n",
      "\t 3 \t 648 \t 63 \t 375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57124385828807867"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Optimized SVM\n",
    "Accuracy is truly horrendous: 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeSVM(X_train, y_train, reg_min_log10=-2, reg_max_log10=2, regularization_type='l1'):\n",
    "    '''\n",
    "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      y_train: A dataframe on which to evaluate the training data\n",
    "      reg_min_log10: log base 10 of the low end of the regularization parameter range.  -2 means 10^-2\n",
    "      reg_max_log10: log base 10 of the high end of the regularization parameter range.  2 means 10^2\n",
    "    Returns:\n",
    "      A fitted SVM classifier.\n",
    "    '''\n",
    "    \n",
    "    model_to_set = LinearSVC(penalty=regularization_type,random_state=0, dual=False)\n",
    "    # consider broadening the param_grid to include different SVM kernels and degrees.  See:\n",
    "    # http://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "    #param_grid = {'C': [10**i for i in range(-reg_min_log10,reg_max_log10)] + [1e30]}\n",
    "    param_grid = {'C':[1]}\n",
    "    model_tuning = GridSearchCV(model_to_set, scoring='f1_weighted',param_grid=param_grid)\n",
    "    \n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print 'best C param for SVM classifier:', model_tuning.best_params_['C']\n",
    "    print 'best_score: ', model_tuning.best_score_\n",
    "        \n",
    "    return model_tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_opt = optimizeSVM(X_train,y_train,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_opt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_accuracy(svm_opt.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeLogistic(X_train, y_train, reg_min_log10=-2, reg_max_log10=2,regularization_type='l1'):\n",
    "    '''\n",
    "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      y_train: A dataframe on which to evaluate the training data\n",
    "      score_func: Scoring function.  Dizzying options here.  Consider:\n",
    "          metrics.accuracy_score\n",
    "          metrics.f1_score\n",
    "    Returns:\n",
    "      A fitted SVM classifier.\n",
    "    '''\n",
    "    \n",
    "    model_to_set = LogisticRegression(penalty=regularization_type)\n",
    "    param_grid = {'C': [10**i for i in range(-reg_min_log10,reg_max_log10)] + [1e30]}\n",
    "    model_tuning = GridSearchCV(model_to_set, param_grid=param_grid,\n",
    "                             scoring='f1_weighted')\n",
    "    \n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print 'best C param for LR classifier:', model_tuning.best_params_['C']\n",
    "    print 'best params: ', model_tuning.best_params_\n",
    "    print 'best_score: ', model_tuning.best_score_\n",
    "        \n",
    "    return model_tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_opt = optimizeLogistic(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_opt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_accuracy(logit_opt.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
