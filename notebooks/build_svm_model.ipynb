{
 "metadata": {
  "name": "",
  "signature": "sha256:797790ec11d4829a6c0e0bc6be31b0a4afdebb58c4aa9f8de485c4349c27838a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('../scripts')\n",
      "from extract_metadata import extract_metadata,label_feature_split\n",
      "from course_utils import trainTest\n",
      "import join_data as jd\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn import svm\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from models import evaluate_accuracy\n",
      "import models\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = extract_metadata('../data/merged_caselevel_data.csv')\n",
      "case_ids = df['caseid']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, ordered_case_ids = jd.construct_sparse_opinion_matrix(case_ids,'../data/docvec_text',10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "shape:  (125, 747276)\n",
        "number of cases 125\n",
        "total time: 5.0588581562\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#match up the labels with the n-grams\n",
      "df = df.set_index('caseid')\n",
      "ordered_df = df.loc[ordered_case_ids,:]\n",
      "#y = np.array(ordered_df['direct1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_rows = int(0.75*len(ordered_case_ids))\n",
      "y = ordered_df['direct1']\n",
      "y_train = np.array(y.iloc[:train_rows])\n",
      "y_test = np.array(y.iloc[train_rows:])\n",
      "X_train = X[:train_rows]\n",
      "X_test = X[train_rows:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "print X_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(93, 747276)\n",
        "(32, 747276)\n",
        "(93,)\n",
        "(32,)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LinearSVC(penalty='l1',random_state=0, dual=False)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l1',\n",
        "     random_state=0, tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_pred = clf.predict(X_train)\n",
      "y_test_pred = clf.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(X_test,y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "0.46875"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_accuracy(y_train,y_train_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t \t pred\n",
        "true \t \t 0 \t 1 \t 2 \t 3\n",
        "\t 0 \t 9 \t 0 \t 0 \t 0\n",
        "\t 1 \t 0 \t 43 \t 0 \t 0\n",
        "\t 2 \t 0 \t 0 \t 6 \t 0\n",
        "\t 3 \t 0 \t 0 \t 0 \t 35\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_accuracy(y_test,y_test_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t \t pred\n",
        "true \t \t 0 \t 1 \t 2 \t 3\n",
        "\t 0 \t 0 \t 1 \t 0 \t 1\n",
        "\t 1 \t 0 \t 8 \t 1 \t 5\n",
        "\t 2 \t 0 \t 3 \t 0 \t 1\n",
        "\t 3 \t 1 \t 4 \t 0 \t 7\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0.46875"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def optimizeSVM(X_train, y_train, regularization_type='l1'):\n",
      "    '''\n",
      "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
      "    Args:\n",
      "      X_train: A dataframe on which to train the features\n",
      "      y_train: A dataframe on which to evaluate the training data\n",
      "      score_func: Scoring function.  Dizzying options here.  Consider:\n",
      "          metrics.accuracy_score\n",
      "          metrics.f1_score\n",
      "    Returns:\n",
      "      A fitted SVM classifier.\n",
      "    '''\n",
      "    \n",
      "    model_to_set = LinearSVC(penalty=regularization_type,random_state=0, dual=False)\n",
      "    # consider broadening the param_grid\n",
      "    # http://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
      "    param_grid = {'estimator__C': [10**i for i in range(0)] + [1e30]}\n",
      "    model_tuning = GridSearchCV(model_to_set, scoring='f1',param_grid=param_grid)\n",
      "    \n",
      "    model_tuning.fit(X_train, y_train)\n",
      "    print 'best C param for LR classifier:', model_tuning.best_params_['estimator__C']\n",
      "    print 'best params: ', model_tuning.best_params_\n",
      "    print 'best_score: ', model_tuning.best_score_\n",
      "        \n",
      "    #return model_tuning.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimizeSVM(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Invalid parameter estimator for estimator LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l1,\n     random_state=0, tol=0.0001, verbose=0)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-27-47ae516f095f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizeSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-25-3019e48bb2d8>\u001b[0m in \u001b[0;36moptimizeSVM\u001b[0;34m(X_train, y_train, regularization_type)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'best C param for LR classifier:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator__C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'best params: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    705\u001b[0m                           \u001b[0;34m\" The params argument will be removed in 0.15.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                           DeprecationWarning)\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                     self.scorer_, self.verbose, **self.fit_params)\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 for train, test in cv)\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit_grid_point\u001b[0;34m(X, y, base_estimator, parameters, train, test, scorer, verbose, loss_func, **fit_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;31m# update parameters of the classifier after a copy of its base structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     raise ValueError('Invalid parameter %s for estimator %s' %\n\u001b[0;32m--> 250\u001b[0;31m                                      (name, self))\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0msub_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0msub_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0msub_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Invalid parameter estimator for estimator LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l1,\n     random_state=0, tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def optimizeLogistic(X_train, y_train, score_func=metrics.f1_score, regularization_type='l1'):\n",
      "    '''\n",
      "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
      "    Args:\n",
      "      X_train: A dataframe on which to train the features\n",
      "      y_train: A dataframe on which to evaluate the training data\n",
      "      score_func: Scoring function.  Dizzying options here.  Consider:\n",
      "          metrics.accuracy_score\n",
      "          metrics.f1_score\n",
      "    Returns:\n",
      "      A fitted SVM classifier.\n",
      "    '''\n",
      "    \n",
      "    model_to_set = OneVsRestClassifier(LinearSVC(penalty='l1',random_state=0, dual=False))\n",
      "    # consider broadening the param_grid\n",
      "    # http://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
      "    param_grid = {'estimator__C': [10**i for i in range(-1,0)] + [1e30]}\n",
      "    model_tuning = GridSearchCV(model_to_set, param_grid=param_grid,\n",
      "                             score_func=score_func)\n",
      "    \n",
      "    model_tuning.fit(X_train, y_train)\n",
      "    print 'best C param for LR classifier:', model_tuning.best_params_['estimator__C']\n",
      "    print 'best params: ', model_tuning.best_params_\n",
      "    print 'best_score: ', model_tuning.best_score_\n",
      "        \n",
      "    #return model_tuning.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def optimizeLogisticRegression(X_train, Y_train, scorer, regularization_type='l2'):\n",
      "    '''Creates a logisitic regression trainied on the given data with an optimized C parameter.\n",
      "    Args:\n",
      "      X_train: A dataframe on which to train the features\n",
      "      Y_train: A dataframe on which to evaluate the training data\n",
      "      scorer: A string or a scoring function used to optimize the C hyperparameter. Use 'roc_auc'\n",
      "        to optimize via roc_auc, and use the following to optimize via F2 score:\n",
      "        ftwo_scorer = metrics.make_scorer(metrics.fbeta_score, beta=2) \n",
      "    Returns:\n",
      "      A fitted logistic regression classifier.\n",
      "    '''\n",
      "    param_grid = {'C': [10**i for i in range(-3,7)] + [1e30]}\n",
      "    lr_classifier = GridSearchCV(linear_model.LogisticRegression(penalty=regularization_type), \n",
      "                                 param_grid=param_grid, scoring=scorer, cv=5)\n",
      "    print 'best C param for LR classifier:', lr_classifier.best_params_['C']\n",
      "    return lr_classifier.fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}