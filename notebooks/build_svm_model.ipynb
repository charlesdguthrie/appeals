{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from extract_metadata import extract_metadata,label_feature_split\n",
    "from course_utils import trainTest\n",
    "import join_data as jd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from models import evaluate_accuracy\n",
    "import models\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cases_df = extract_metadata('../data/merged_caselevel_data.csv')\n",
    "case_ids = cases_df['caseid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO: \n",
    "- Run on larger data set \n",
    "- lower min-n-gram count\n",
    "- try TF-IDF True or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (1403, 2389)\n",
      "number of cases 1403\n",
      "total time: 50.4344818592\n"
     ]
    }
   ],
   "source": [
    "X, ordered_case_ids,y = jd.construct_sparse_opinion_matrix(cases_df,'../data/docvec_text',100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split(X,y, pct_train):\n",
    "    train_rows = int(pct_train*len(y))\n",
    "    y_train = np.array(y[:train_rows])\n",
    "    y_test = np.array(y[train_rows:])\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    case_ids_train = ordered_case_ids[:train_rows]\n",
    "    case_ids_test = ordered_case_ids[train_rows:]\n",
    "    return X_train,y_train,case_ids_train,X_test,y_test,case_ids_test\n",
    "\n",
    "X_train,y_train,case_ids_train,X_test,y_test,case_ids_test = train_test_split(X,y,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1052, 2389)\n",
      "(351, 2389)\n",
      "(1052,)\n",
      "(351,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(penalty='l1',random_state=0, dual=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3903133903133903"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 464 \t 1 \t 1\n",
      "\t 2 \t 0 \t 174 \t 1\n",
      "\t 3 \t 0 \t 1 \t 410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99619771863117867"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 84 \t 38 \t 67\n",
      "\t 2 \t 24 \t 15 \t 26\n",
      "\t 3 \t 39 \t 20 \t 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3903133903133903"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO:\n",
    "- Get test score\n",
    "- Get baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeSVM(X_train, y_train, regularization_type='l1'):\n",
    "    '''\n",
    "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      y_train: A dataframe on which to evaluate the training data\n",
    "      score_func: Scoring function.  Dizzying options here.  Consider:\n",
    "          metrics.accuracy_score\n",
    "          metrics.f1_score\n",
    "    Returns:\n",
    "      A fitted SVM classifier.\n",
    "    '''\n",
    "    \n",
    "    model_to_set = LinearSVC(penalty=regularization_type,random_state=0, dual=False)\n",
    "    # consider broadening the param_grid to include different SVM kernels and degrees.  See:\n",
    "    # http://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "    param_grid = {'C': [10**i for i in range(-3,7)] + [1e30]}\n",
    "    model_tuning = GridSearchCV(model_to_set, scoring='f1_weighted',param_grid=param_grid)\n",
    "    \n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print 'best C param for SVM classifier:', model_tuning.best_params_['C']\n",
    "    print 'best_score: ', model_tuning.best_score_\n",
    "        \n",
    "    #return model_tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C param for SVM classifier: 0.01\n",
      "best_score:  0.47986857994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "optimizeSVM(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Test Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeLogistic(X_train, y_train, score_func=metrics.f1_score, regularization_type='l1'):\n",
    "    '''\n",
    "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      y_train: A dataframe on which to evaluate the training data\n",
    "      score_func: Scoring function.  Dizzying options here.  Consider:\n",
    "          metrics.accuracy_score\n",
    "          metrics.f1_score\n",
    "    Returns:\n",
    "      A fitted SVM classifier.\n",
    "    '''\n",
    "    \n",
    "    model_to_set = OneVsRestClassifier(LinearSVC(penalty='l1',random_state=0, dual=False))\n",
    "    # consider broadening the param_grid\n",
    "    # http://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "    param_grid = {'estimator__C': [10**i for i in range(-1,0)] + [1e30]}\n",
    "    model_tuning = GridSearchCV(model_to_set, param_grid=param_grid,\n",
    "                             score_func=score_func)\n",
    "    \n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print 'best C param for LR classifier:', model_tuning.best_params_['estimator__C']\n",
    "    print 'best params: ', model_tuning.best_params_\n",
    "    print 'best_score: ', model_tuning.best_score_\n",
    "        \n",
    "    #return model_tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeLogisticRegression(X_train, Y_train, scorer, regularization_type='l2'):\n",
    "    '''Creates a logisitic regression trainied on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      Y_train: A dataframe on which to evaluate the training data\n",
    "      scorer: A string or a scoring function used to optimize the C hyperparameter. Use 'roc_auc'\n",
    "        to optimize via roc_auc, and use the following to optimize via F2 score:\n",
    "        ftwo_scorer = metrics.make_scorer(metrics.fbeta_score, beta=2) \n",
    "    Returns:\n",
    "      A fitted logistic regression classifier.\n",
    "    '''\n",
    "    param_grid = {'C': [10**i for i in range(-3,7)] + [1e30]}\n",
    "    lr_classifier = GridSearchCV(linear_model.LogisticRegression(penalty=regularization_type), \n",
    "                                 param_grid=param_grid, scoring=scorer, cv=5)\n",
    "    print 'best C param for LR classifier:', lr_classifier.best_params_['C']\n",
    "    return lr_classifier.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
